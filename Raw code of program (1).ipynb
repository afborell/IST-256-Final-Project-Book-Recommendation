{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prerequisites\n",
    "!pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "#GoodreadsAPI key\n",
    "key = \"W6xebHZh54bUGgMJCyWxQ\"\n",
    "endpoint = \"https://www.goodreads.com/\"\n",
    "\n",
    "# Get input from the user, search the Goodreads API for the string and choose the first result.\n",
    "\n",
    "fav_book = input(\"What is the most recently read book that you've enjoyed? \")\n",
    "search = requests.get(f\"{endpoint}search.xml?key={key}&q={fav_book}\")\n",
    "xml_str = search.content\n",
    "pie = BeautifulSoup(xml_str, 'lxml-xml')\n",
    "result = pie.find('work')\n",
    "\n",
    "#we don't need this data to make an effective search. We just need the ID.\n",
    "#firsttitle = BeautifulSoup(str(result.find('title')),\"lxml\").get_text()\n",
    "#firstauthor = BeautifulSoup(str(result.find('name')),\"lxml\").get_text()\n",
    "firstid = BeautifulSoup(str(result.find('id')),\"lxml\").get_text()\n",
    "\n",
    "#create empty lists for the incoming recommendations\n",
    "rec_titles=[]\n",
    "rec_authors=[] \n",
    "rec_ratings=[]\n",
    "\n",
    "#use the book ID gathered with the goodreads API to open the Goodreads \n",
    "#recommendations page, which is not accesscible using the API.\n",
    "url=f'{endpoint}book/similar/{firstid}'\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "#Return the search to the user\n",
    "resulttitle = soup.title\n",
    "resulttitle = str(resulttitle)\n",
    "cleanresulttitle = BeautifulSoup(resulttitle, \"lxml\").get_text()\n",
    "\n",
    "print(\"You are looking for:\",cleanresulttitle)\n",
    "\n",
    "#loop against results shown on webpage and add them to respective lists\n",
    "for a in soup.findAll('div', attrs={'class':'responsiveBook'}):\n",
    "#Titles\n",
    "    title=str(a.find('span', attrs={'itemprop':'name'}))\n",
    "    cleantitle = BeautifulSoup(title, \"lxml\").get_text()\n",
    "    rec_titles.append(cleantitle)\n",
    "#Authors\n",
    "    author=str(a.find('span', attrs={'itemprop':'author'}))\n",
    "    cleanauthor = BeautifulSoup(author, \"lxml\").get_text()\n",
    "    rec_authors.append(cleanauthor)\n",
    "#Ratings\n",
    "    rating=str(a.find('div', attrs={'class':'communityRating'})) #needs more code to catch arialabel\n",
    "    cleanrating = BeautifulSoup(rating, \"lxml\").get_text()\n",
    "    rec_ratings.append(cleanrating)\n",
    "\n",
    "#Create a dataframe and export to csv just in case!\n",
    "\n",
    "df = pd.DataFrame({'Title':rec_titles,'Author':rec_authors,'Rating':rec_ratings}) \n",
    "df.to_csv('recommendations.csv', index=False, encoding='utf-8')\n",
    "\n",
    "#Display the final result\n",
    "print(\"Here are 5 recommendations you are sure to enjoy!\")\n",
    "df[1:6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
